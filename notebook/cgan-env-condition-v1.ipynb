{"cells":[{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3387,"status":"ok","timestamp":1721055234476,"user":{"displayName":"Thuận Lương","userId":"06908978135761943815"},"user_tz":-420},"id":"s-wnJpVXLtB3","outputId":"d71f3831-1b83-4c8c-fb0a-c86cf3740088"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1721055234477,"user":{"displayName":"Thuận Lương","userId":"06908978135761943815"},"user_tz":-420},"id":"i9B11zfiLsUL"},"outputs":[],"source":["import keras\n","from keras.models import Sequential, Model\n","from keras.layers import Input, Dense, Dropout, Activation, Flatten, LeakyReLU, Embedding\n","from keras.optimizers import Adam, RMSprop\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import random\n","from tqdm import tqdm_notebook, tqdm\n","from numpy import zeros, ones\n","from numpy.random import randn, randint\n","import os"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1833,"status":"ok","timestamp":1721055212841,"user":{"displayName":"Thuận Lương","userId":"06908978135761943815"},"user_tz":-420},"id":"moBOnzWFLsUP","outputId":"e2a7055f-2412-4f4a-8d6b-73493a7b0963"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Stn Id    Stn Name        CIMIS Region      Date  ETo (in)  Precip (in)  \\\n","0       2  FivePoints  San Joaquin Valley  1/1/2018      0.06          0.0   \n","\n","   Sol Rad (Ly/day)  Avg Vap Pres (mBars)  Max Air Temp (F)  Min Air Temp (F)  \\\n","0             219.0                   7.3              63.4              35.3   \n","\n","   Avg Air Temp (F)  Max Rel Hum (%)  Min Rel Hum (%)  Avg Rel Hum (%)  \\\n","0              47.8             82.0             46.0             65.0   \n","\n","   Dew Point (F)  Avg Wind Speed (mph)  Wind Run (miles)  Avg Soil Temp (F)  \\\n","0           36.6                   3.3              78.3               51.1   \n","\n","   Target  \n","0       0  "],"text/html":["\n","  <div id=\"df-d0c4d420-e8d8-4a55-942e-a68aa9d7c7db\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Stn Id</th>\n","      <th>Stn Name</th>\n","      <th>CIMIS Region</th>\n","      <th>Date</th>\n","      <th>ETo (in)</th>\n","      <th>Precip (in)</th>\n","      <th>Sol Rad (Ly/day)</th>\n","      <th>Avg Vap Pres (mBars)</th>\n","      <th>Max Air Temp (F)</th>\n","      <th>Min Air Temp (F)</th>\n","      <th>Avg Air Temp (F)</th>\n","      <th>Max Rel Hum (%)</th>\n","      <th>Min Rel Hum (%)</th>\n","      <th>Avg Rel Hum (%)</th>\n","      <th>Dew Point (F)</th>\n","      <th>Avg Wind Speed (mph)</th>\n","      <th>Wind Run (miles)</th>\n","      <th>Avg Soil Temp (F)</th>\n","      <th>Target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2</td>\n","      <td>FivePoints</td>\n","      <td>San Joaquin Valley</td>\n","      <td>1/1/2018</td>\n","      <td>0.06</td>\n","      <td>0.0</td>\n","      <td>219.0</td>\n","      <td>7.3</td>\n","      <td>63.4</td>\n","      <td>35.3</td>\n","      <td>47.8</td>\n","      <td>82.0</td>\n","      <td>46.0</td>\n","      <td>65.0</td>\n","      <td>36.6</td>\n","      <td>3.3</td>\n","      <td>78.3</td>\n","      <td>51.1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d0c4d420-e8d8-4a55-942e-a68aa9d7c7db')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-d0c4d420-e8d8-4a55-942e-a68aa9d7c7db button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-d0c4d420-e8d8-4a55-942e-a68aa9d7c7db');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df"}},"metadata":{},"execution_count":3}],"source":["path=\"/content/drive/MyDrive/paper/env_conditions/data/prepared_data/all_conditions.csv\"\n","df = pd.read_csv(path)\n","df = df.drop(['Unnamed: 0'], axis=1)\n","df.isna().sum()\n","df.head(1)"]},{"cell_type":"markdown","metadata":{"id":"rcavbPSgLsUQ"},"source":["# prepare data"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"7fOrwCqZLsUS","executionInfo":{"status":"ok","timestamp":1721055234947,"user_tz":-420,"elapsed":474,"user":{"displayName":"Thuận Lương","userId":"06908978135761943815"}}},"outputs":[],"source":["df_date = df['Date'].values\n","day, month, year = [], [], []\n","for i in df_date:\n","    data = i.split('/')\n","    day.append(int(data[1]))\n","    month.append(int(data[0]))\n","    year.append(int(data[2]))\n","\n","temp = pd.DataFrame({'year': year,'month': month,'day': day})\n","#temp = pd.to_datetime(temp)\n","#df['Date'] = temp"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"1ILu7bqCLsUS","executionInfo":{"status":"ok","timestamp":1721055234947,"user_tz":-420,"elapsed":5,"user":{"displayName":"Thuận Lương","userId":"06908978135761943815"}}},"outputs":[],"source":["df1 = df.drop(['Stn Id', 'Stn Name', 'CIMIS Region', 'Date'], axis=1)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"D5zhDkJHLsUS","executionInfo":{"status":"ok","timestamp":1721055235855,"user_tz":-420,"elapsed":912,"user":{"displayName":"Thuận Lương","userId":"06908978135761943815"}}},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","X = df.drop(['Target'], axis=1)\n","Y = df['Target']\n","\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n","\n","X_train.reset_index(drop=True, inplace=True)\n","X_test.reset_index(drop=True, inplace=True)\n","\n","Y_train.reset_index(drop=True, inplace=True)\n","Y_test.reset_index(drop=True, inplace=True)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"JD3iqtR2LsUT","executionInfo":{"status":"ok","timestamp":1721055235855,"user_tz":-420,"elapsed":4,"user":{"displayName":"Thuận Lương","userId":"06908978135761943815"}}},"outputs":[],"source":["# from sklearn.preprocessing import LabelEncoder\n","# category_cols = ['Stn Name', 'CIMIS Region']\n","# temp1 = X_train.get(category_cols[0])\n","# temp2 = X_train.get(category_cols[1])\n","\n","\n","# encoder1 = LabelEncoder()\n","# encoder1.fit(temp1)\n","# temp1 = encoder1.transform(temp1)\n","\n","# encoder2 = LabelEncoder()\n","# encoder2.fit(temp2)\n","# temp2 = encoder2.transform(temp2)\n","\n","# X_train1 = X_train\n","# X_train1[category_cols[0]] = temp1\n","# X_train1[category_cols[1]] = temp2"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"1ij3u90GLsUU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"error","timestamp":1721055236506,"user_tz":-420,"elapsed":653,"user":{"displayName":"Thuận Lương","userId":"06908978135761943815"}},"outputId":"a9b10ce5-cf15-4c6e-d138-4f00d20b3976"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"could not convert string to float: 'Pleasanton'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-214a58847efd>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mencoder_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mencoder_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mX_train1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mfirst_pass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    467\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfirst_pass\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    877\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m                 raise ValueError(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"numpy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"numpy.array_api\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1996\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m         if (\n\u001b[1;32m   2000\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Pleasanton'"]}],"source":["from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import LabelEncoder\n","\n","X_train1, Y_train1 = X_train, Y_train\n","\n","encoder_x = MinMaxScaler()\n","encoder_x.fit(X_train1)\n","\n","X_train1 = encoder_x.transform(X_train1)\n","\n","encoder_y = LabelEncoder()\n","encoder_y.fit(Y_train1)\n","\n","Y_train1 = encoder_y.transform(Y_train1)"]},{"cell_type":"markdown","metadata":{"id":"VujPkOv0LsUU"},"source":["# Build model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-X0SJVeLLsUV","executionInfo":{"status":"aborted","timestamp":1721055236507,"user_tz":-420,"elapsed":20,"user":{"displayName":"Thuận Lương","userId":"06908978135761943815"}}},"outputs":[],"source":["from tqdm import tqdm_notebook\n","import matplotlib\n","import matplotlib.pylab as plt\n","from math import ceil\n","import numpy as np\n","from keras.models import Sequential, Model\n","from keras.layers import Input, ReLU, LeakyReLU, Dense, Conv2D, Conv2DTranspose, Concatenate, Dropout\n","from keras.optimizers import SGD, Adam\n","from keras.initializers import RandomNormal"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"egT4fBTdLsUV","executionInfo":{"status":"aborted","timestamp":1721055236507,"user_tz":-420,"elapsed":20,"user":{"displayName":"Thuận Lương","userId":"06908978135761943815"}}},"outputs":[],"source":["def build_generator(n_classes, z_dim = 100):\n","    output_g = len(X_train1[0])\n","\n","    #block1\n","    in_label = Input(shape=(1,))\n","    #in_label = Embedding(n_classes, 50)(in_label)\n","    blockA1 = Dense(128, activation=LeakyReLU(alpha=0.2))(in_label)\n","    blockA1 = Dense(64, activation=LeakyReLU(alpha=0.2))(blockA1)\n","    blockA1 = Dense(32, activation=LeakyReLU(alpha=0.2))(blockA1)\n","\n","    #block2\n","    in_data = Input(shape=(z_dim,))\n","    blockA2 = Dense(1024, activation=LeakyReLU(alpha=0.2))(in_data)\n","    blockA2 = Dense(512, activation=LeakyReLU(alpha=0.2))(blockA2)\n","    blockA2 = Dense(224, activation=LeakyReLU(alpha=0.2))(blockA2)\n","\n","    #Concat\n","    merge = Concatenate()([blockA2, blockA1])\n","\n","    #main\n","    g = Dense(128, activation=LeakyReLU(alpha=0.2))(merge)\n","    g = Dense(63, activation=LeakyReLU(alpha=0.2))(g)\n","    g = Dense(32, activation=LeakyReLU(alpha=0.2))(g)\n","    output = Dense(output_g, activation='sigmoid')(g)\n","\n","    #Define model\n","    model = Model([in_data, in_label], output)\n","\n","\n","    print('Build Generator')\n","    print(model.summary())\n","\n","    return model\n","\n","def build_discriminator(n_classes):\n","    input_d = len(X_train1[0])\n","\n","    #block1\n","    in_label = Input(shape=(1,))\n","    #in_label = Embedding(n_classes, 50)(in_label)\n","    blockA1 = Dense(64, activation=LeakyReLU(alpha=0.2))(in_label)\n","    blockA1 = Dense(32, activation=LeakyReLU(alpha=0.2))(blockA1)\n","    blockA1 = Dense(16, activation=LeakyReLU(alpha=0.2))(blockA1)\n","\n","    #block2\n","    in_data = Input(shape=(input_d,))\n","    blockA2 = Dense(256, activation=LeakyReLU(alpha=0.2))(in_data)\n","    blockA2 = Dropout(0.5)(blockA2)\n","    blockA2 = Dense(128, activation=LeakyReLU(alpha=0.2))(blockA2)\n","    blockA2 = Dropout(0.5)(blockA2)\n","    blockA2 = Dense(48, activation=LeakyReLU(alpha=0.2))(blockA2)\n","    blockA2 = Dropout(0.4)(blockA2)\n","\n","    #Concat\n","    merge = Concatenate()([blockA2, blockA1])\n","\n","    #main\n","    d = Dense(16, activation=LeakyReLU(alpha=0.2))(merge)\n","    d = Dropout(0.3)(d)\n","    output = Dense(1, activation='sigmoid')(d)\n","\n","    #define model\n","    model = Model([in_data, in_label], output)\n","    model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n","\n","    print('Build discriminator')\n","    print(model.summary())\n","\n","    return model\n","\n","\n","def build_gan(g_model, d_model):\n","    #Not train d_model\n","    d_model.trainable = False\n","\n","    gen_noise, gen_label = g_model.input\n","    gen_output = g_model.output\n","    gan_output = d_model([gen_output, gen_label])\n","    model = Model([gen_noise, gen_label], gan_output)\n","    model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n","\n","    print('Build GAN')\n","    print(model.summary())\n","\n","    return model\n","\n","\n","def load_real_samples():\n","\treturn [X_train1, Y_train1]\n","\n","\n","def generate_real_samples(dataset, n_samples):\n","\t# split into images and labels\n","\tdata, labels = dataset\n","\t# choose random instances\n","\tix = randint(0, data.shape[0], n_samples)\n","\t# select images and labels\n","\tX, labels = data[ix], labels[ix]\n","\t# generate class labels\n","\ty = ones((n_samples, 1))\n","\treturn [X, labels], y\n","\n","\n","def generate_latent_points(latent_dim, n_samples, n_classes=2):\n","\t# generate points in the latent space\n","\tx_input = randn(latent_dim * n_samples)\n","\t# reshape into a batch of inputs for the network\n","\tz_input = x_input.reshape(n_samples, latent_dim)\n","\t# generate labels\n","\tlabels = randint(0, n_classes, n_samples)\n","\treturn [z_input, labels]\n","\n","\n","def generate_fake_samples(generator, latent_dim, n_samples):\n","    # generate points in latent space\n","    z_input, labels_input = generate_latent_points(latent_dim, n_samples)\n","    # predict outputs\n","    data = generator.predict([z_input, labels_input])\n","    # create class labels\n","    y = zeros((n_samples, 1))\n","    return [data, labels_input], y\n","\n","\n","# train the generator and discriminator\n","def train(g_model, d_model, gan_model, dataset, latent_dim=100, n_epochs=100, n_batch=512):\n","    bat_per_epo = int(dataset[0].shape[0] / n_batch)\n","    half_batch = int(n_batch / 2)\n","    # manually enumerate epochs\n","    for i in range(n_epochs):\n","      # enumerate batches over the training set\n","      for j in range(bat_per_epo):\n","          # get randomly selected 'real' samples\n","          [X_real, labels_real], y_real = generate_real_samples(dataset, half_batch)\n","\n","          d_model.trainable = True\n","          # update discriminator model weights\n","          d_loss1, _ = d_model.train_on_batch([X_real, labels_real], y_real)\n","          # generate 'fake' examples\n","          [X_fake, labels], y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n","          # update discriminator model weights\n","          d_loss2, _ = d_model.train_on_batch([X_fake, labels], y_fake)\n","\n","          d_model.trainable = False\n","          # prepare points in latent space as input for the generator\n","          [z_input, labels_input] = generate_latent_points(latent_dim, n_batch)\n","          # create inverted labels for the fake samples\n","          y_gan = ones((n_batch, 1))\n","          # update the generator via the discriminator's error\n","          g_loss, acc = gan_model.train_on_batch([z_input, labels_input], y_gan)\n","          # summarize loss on this batch\n","          print(f\"G acc: {acc}\\nG loss: {g_loss}\\nD loss 1: {d_loss1}\\nD loss 2: {d_loss2}\")\n","          print('>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' %\n","              (i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n","\n","      js = open('/content/drive/MyDrive/paper/env_conditions/Model/CGAN/gan_20240715.log', 'a')\n","      js.write(f'-----------------------------------------------Epoch {e}-----------------------------------------------\\n')\n","      js.write(f'd loss: {d_loss}\\t\\t\\td acc: {d_acc}\\n')\n","      js.write(f'g loss: {g_loss}\\t\\t\\tg acc: {g_acc}\\n')\n","      js.write('\\n\\n')\n","      js.close()\n","            # save the generator model\n","      g_model.save(f'/content/drive/MyDrive/paper/env_conditions/Model/CGAN/cgan_generator_{i}.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"Tu-Swf23LsUW","executionInfo":{"status":"aborted","timestamp":1721055236508,"user_tz":-420,"elapsed":17,"user":{"displayName":"Thuận Lương","userId":"06908978135761943815"}}},"outputs":[],"source":["# size of the latent space\n","latent_dim = 100\n","n_classes = 2\n","# create the discriminator\n","d_model = build_discriminator(n_classes)\n","# create the generator\n","g_model = build_generator(n_classes,latent_dim)\n","# create the gan\n","gan_model = build_gan(g_model, d_model)\n","# load data\n","dataset = load_real_samples()\n","# train model\n","train(g_model, d_model, gan_model, dataset, latent_dim)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"quwSCREU1gEl","executionInfo":{"status":"aborted","timestamp":1721055236510,"user_tz":-420,"elapsed":19,"user":{"displayName":"Thuận Lương","userId":"06908978135761943815"}}},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5380900,"sourceId":8942647,"sourceType":"datasetVersion"}],"dockerImageVersionId":30746,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}